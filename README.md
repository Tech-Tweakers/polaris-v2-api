# ğŸŒŸ Polaris AI v3 â€“ Advanced Multi-Modal AI Assistant

<div align="center">

<a href="#"><img src="https://img.shields.io/badge/Polaris-AI%20Assistant-blue?style=for-the-badge&logo=robot" alt="Polaris Logo"/></a>
<a href="https://python.org"><img src="https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python" alt="Python"/></a>
<a href="https://fastapi.tiangolo.com"><img src="https://img.shields.io/badge/FastAPI-Latest-green?style=flat-square&logo=fastapi" alt="FastAPI"/></a>
<a href="https://mongodb.com"><img src="https://img.shields.io/badge/MongoDB-6.0-green?style=flat-square&logo=mongodb" alt="MongoDB"/></a>
<a href="https://docker.com"><img src="https://img.shields.io/badge/Docker-Compose-blue?style=flat-square&logo=docker" alt="Docker"/></a>
<a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-yellow?style=flat-square" alt="License"/></a>

<br><br>

**A sophisticated AI assistant that combines conversational AI, voice synthesis, document processing, and multi-platform integration.**

</div>
---

## ğŸ§­ Ãndice

- [ğŸ¯ Overview](#-overview)
- [âœ¨ Key Features](#-key-features)
  - [ğŸ¤– Multi-Modal AI Processing](#-multi-modal-ai-processing)
  - [ğŸ§  Advanced Memory System](#-advanced-memory-system)
  - [ğŸš€ High-Performance Inference](#-high-performance-inference)
  - [ğŸŒ Multi-Platform Integration](#-multi-platform-integration)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Quick Start](#-quick-start)
  - [ğŸ”§ Prerequisites](#-prerequisites)
  - [ğŸ¯ One-Command Setup](#-one-command-setup)
- [ğŸ› ï¸ Manual Installation](#ï¸-manual-installation)
- [âš™ï¸ Configuration](#ï¸-configuration)
  - [.env â€“ Polaris API](#env--polaris-api)
  - [.env â€“ Polaris Integrations](#env--polaris-integrations)
- [ğŸ§ª Testing](#-testing)
- [â¤ï¸ Credits](#-desenvolvido-com--pela-equipe-tech-tweakers)

---

## ğŸ¯ Overview

**Polaris** is a next-generation AI assistant that integrates cutting-edge technologies into a unified, scalable platform. It delivers intelligent responses via Telegram, web interfaces, and mobile apps.

---

## âœ¨ Key Features

### ğŸ¤– Multi-Modal AI Processing
- Text-to-speech with multiple engines: ElevenLabs, Coqui, Groq  
- Speech-to-text with Whisper  
- PDF document ingestion and vectorization  
- Image analysis (basic support)

### ğŸ§  Advanced Memory System
- Dual-layer memory (short-term + long-term)  
- Persistent memory via MongoDB  
- Semantic search via ChromaDB  
- LangChain integration for context preservation

### ğŸš€ High-Performance Inference
- Local model support via `llama.cpp`  
- Remote inference with Groq API (LLaMA 3 70B)  
- Configurable inference parameters  
- Optimized for multi-core systems

### ğŸŒ Multi-Platform Integration
- Telegram bot  
- REST API  
- Web UI support  
- Mobile-ready architecture

---

## ğŸ“ Project Structure

```
polaris-v3/
â”œâ”€â”€ ğŸš€ polaris_api/          # Core Polaris API (LLM, Prompt, Memory)
â”‚   â”œâ”€â”€ polaris_main.py         # ğŸ”§ Main API logic and request handling
â”‚   â”œâ”€â”€ polaris_logger.py       # ğŸ“œ Structured logging for requests/events
â”‚   â”œâ”€â”€ polaris_keywords.py     # ğŸ§  Long-term keyword memory system
â”‚   â”œâ”€â”€ polaris_prompt.py       # ğŸ¯ AI instruction and system prompts
â”‚   â”œâ”€â”€ llm_loader.py           # ğŸ” LLM router and model selection logic
â”‚   â”œâ”€â”€ llm_local.py            # ğŸ  Local inference via llama.cpp
â”‚   â”œâ”€â”€ llm_groq.py             # â˜ï¸ Remote inference via Groq API
â”‚   â”œâ”€â”€ requirements.txt        # ğŸ“¦ Python dependencies
â”‚   â””â”€â”€ .env                    # ğŸ” API environment variables
â”œâ”€â”€ ğŸ”— polaris_integrations/ # Bridges to external services (voice, audio, etc.)
â”‚   â”œâ”€â”€ main.py                 # ğŸ”Œ Entry point for integrations (TTS, Telegram, etc.)
â”‚   â”œâ”€â”€ tts_router.py           # ğŸ—£ï¸ Smart TTS engine dispatcher
â”‚   â”œâ”€â”€ tts_engines/
â”‚   â”‚ â”œâ”€â”€ coqui.py              # ğŸ™ï¸ Local voice synthesis (XTTS)
â”‚   â”‚ â”œâ”€â”€ eleven.py             # ğŸ§ ElevenLabs cloud-based TTS
â”‚   â”‚ â””â”€â”€ groq.py               # ğŸ¤ Groq PlayAI TTS integration
â”‚   â”œâ”€â”€ polaris-voice.wav       # ğŸ¼ Custom voice reference sample
â”‚   â”œâ”€â”€ requirements.txt        # ğŸ“¦ Integration dependencies
â”‚   â””â”€â”€ .env                    # ğŸ” Integration environment config
â”œâ”€â”€ ğŸ³ polaris_setup/        # Infra, benchmarking, and OS prep
â”‚   â”œâ”€â”€ data-flush.yml          # ğŸ› ï¸ Clean UP Memory Script
â”‚   â”œâ”€â”€ mongodb-compose.yml     # ğŸ—„ï¸ MongoDB container orchestration
â”‚   â”œâ”€â”€ polaris-os-tunner.sh    # ğŸ› ï¸ System tuning script (Debian/Ubuntu)
â”‚   â”œâ”€â”€ polaris-real-tests.py   # ğŸ§ª Realistic conversational stress test
â”‚   â””â”€â”€ polaris-stress-tests.py # ğŸ“ˆ Multi-session synthetic load tester
â”œâ”€â”€ ğŸ“– local-setup.sh           # ğŸš€ Interactive one-command setup script
â””â”€â”€ ğŸ§ª Makefile                 # ğŸ› ï¸ Dev workflow commands and automation
```

---

## ğŸš€ Quick Start

### ğŸ”§ Prerequisites

- Python 3.10+  
- Docker & Docker Compose  
- 16GB+ RAM (for local inference)  
- NVIDIA GPU (opcional)

### ğŸ¯ One-Command Setup

```bash
git clone https://github.com/Tech-Tweakers/polaris-v3.git
cd polaris-v3
./local-setup.sh
```

The interactive setup will:
- Install dependencies
- Create .env files
- Download AI models
- Start all services
- Configure webhooks
- Launch the application

---

## ğŸ› ï¸ Manual Installation

<details>
<summary>Click to view manual installation instructions</summary>

**1. Setup Dependencies**

```bash
make install
```

**2. Create Environment Files*

```bash
make create-env-api
make create-env-bot
```

**3. Download LLM Model for Local Inferences**

```bash
make download-model
```

**4. Setup and Start MongoDB**

```bash
make start-db
```

**5. Start All Services**

```bash
make start-all
```

</details>

---

## âš™ï¸ Configuration

### `.env` â€“ Polaris API

```env
# Model settings
USE_LOCAL_LLM=False

MODEL_PATH="../models/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf"
NUM_CORES=16
MODEL_CONTEXT_SIZE=4096
MODEL_BATCH_SIZE=1

# ConfiguraÃ§Ã£o de histÃ³rico
MONGODB_HISTORY=10
LANGCHAIN_HISTORY=20

# HiperparÃ¢metros do modelo
TEMPERATURE=0.3
TOP_P=0.7
TOP_K=70
FREQUENCY_PENALTY=3

# ConfiguraÃ§Ã£o do MongoDB
MONGO_URI="mongodb://admin:admin123@localhost:27017/polaris_db?authSource=admin"
HF_TOKEN="hf_your-api-key"
GROQ_API_KEY="gsk_your-api-key"
```

### `.env` â€“ Polaris Integrations

```env
TELEGRAM_TOKEN="098098098:your-telegram-bot-token"
POLARIS_API_URL="http://192.168.1.104:8000/inference/"
HF_TOKEN="hf_your-huggingface-api-key"
COQUI_SPEAKER_WAV="polaris-voice.wav"
PUBLIC_URL="https://suitable-actually-kw-rescue.trycloudflare.com"

TTS_ENGINE="eleven"  # or coqui or groq

ELEVEN_API_KEY="sk_your-eleven-labs-api-key"
ELEVEN_VOICE_ID="yM93hbw8Qtvdma2wCnJG"
ELEVEN_MODEL_ID="eleven_multilingual_v2"

GROQ_API_KEY="gsk_your-groq-api-key"
```

---

## ğŸ§ª Testing

**API Test:**

```bash
curl -X POST http://localhost:8000/inference/   -H "Content-Type: application/json"   -d '{"prompt": "Hello, Polaris!", "session_id": "test123"}'
```
---

Developed with â¤ï¸ by **Tech-Tweakers** team.

