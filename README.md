# ğŸŒŸ Polaris AI v2.1 â€“ Multi-Modal AI Assistant

<div align="center">

<a href="#"><img src="https://img.shields.io/badge/Polaris-v2.1%20AI%20Assistant-blue?style=for-the-badge&logo=robot" alt="Polaris v2.1 Logo"/></a>
<a href="https://python.org"><img src="https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python" alt="Python"/></a>
<a href="https://fastapi.tiangolo.com"><img src="https://img.shields.io/badge/FastAPI-Latest-green?style=flat-square&logo=fastapi" alt="FastAPI"/></a>
<a href="https://mongodb.com"><img src="https://img.shields.io/badge/MongoDB-4.0-green?style=flat-square&logo=mongodb" alt="MongoDB"/></a>
<a href="https://docker.com"><img src="https://img.shields.io/badge/Docker-Compose-blue?style=flat-square&logo=docker" alt="Docker"/></a>
<a href="https://groq.com"><img src="https://img.shields.io/badge/Groq-API-orange?style=flat-square&logo=groq" alt="Groq"/></a>
<a href="https://elevenlabs.io"><img src="https://img.shields.io/badge/ElevenLabs-TTS-purple?style=flat-square&logo=elevenlabs" alt="ElevenLabs"/></a>
<a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-yellow?style=flat-square" alt="License"/></a>

**A sophisticated AI assistant that combines conversational AI, voice synthesis, document processing, and multi-platform integration.**

[![GitHub release](https://img.shields.io/github/v/release/Tech-Tweakers/polaris-v2-api)](https://github.com/Tech-Tweakers/polaris-v2-api/releases)
[![GitHub stars](https://img.shields.io/github/stars/Tech-Tweakers/polaris-v2-api)](https://github.com/Tech-Tweakers/polaris-v2-api/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/Tech-Tweakers/polaris-v2-api)](https://github.com/Tech-Tweakers/polaris-v2-api/network)



</div>

- [ğŸ¯ Overview](#-overview)
- [âœ¨ Key Features](#-key-features)
  - [ğŸ¤– Multi-Modal AI Processing](#-multi-modal-ai-processing)
  - [ğŸ§  Advanced Memory System](#-advanced-memory-system)
  - [ğŸš€ High-Performance Inference](#-high-performance-inference)
  - [ğŸŒ Multi-Platform Integration](#-multi-platform-integration)
  - [ğŸ™ï¸ Advanced Voice Processing](#ï¸-advanced-voice-processing)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Quick Start](#-quick-start)
  - [ğŸ”§ Prerequisites](#-prerequisites)
  - [ğŸ¯ One-Command Setup](#-one-command-setup)
- [ğŸ› ï¸ Manual Installation](#ï¸-manual-installation)
- [âš™ï¸ Configuration](#ï¸-configuration)
  - [.env â€“ Polaris API](#env--polaris-api)
  - [.env â€“ Polaris Integrations](#env--polaris-integrations)
- [ğŸ§ª Testing](#-testing)
- [ğŸ“Š Monitoring & Metrics](#-monitoring--metrics)
- [ğŸ”§ Development](#-development)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“ Changelog](#-changelog)
- [â¤ï¸ Credits](#-desenvolvido-com--pela-equipe-tech-tweakers)


## ğŸ¯ Overview

**Polaris v2.1** is a next-generation AI assistant that integrates cutting-edge technologies into a unified, scalable platform. It delivers intelligent responses via Telegram, web interfaces, and mobile apps with enhanced voice processing capabilities and improved performance.

### ğŸ†• What's New in v2.1
- **Enhanced Voice Processing**: Improved TTS engines with better quality and speed
- **Advanced Memory Management**: Optimized memory usage and faster context retrieval
- **Better Error Handling**: More robust error handling and recovery mechanisms
- **Performance Improvements**: Faster inference and reduced latency
- **Enhanced Documentation**: Comprehensive setup and configuration guides


## âœ¨ Key Features

### ğŸ¤– Multi-Modal AI Processing
- **Text-to-Speech** with multiple engines: ElevenLabs, Coqui XTTS, Groq PlayAI
- **Speech-to-Text** with Whisper integration for voice commands
- **PDF Document Processing** with vectorization and semantic search
- **Image Analysis** with basic support for visual content
- **Multi-language Support** with automatic language detection

### ğŸ§  Advanced Memory System
- **Dual-layer Memory Architecture**: Short-term + long-term memory layers
- **Persistent Storage**: MongoDB-based memory persistence
- **Semantic Search**: ChromaDB integration for intelligent context retrieval
- **LangChain Integration**: Advanced context preservation and management
- **Keyword Extraction**: Automatic keyword identification and storage

### ğŸš€ High-Performance Inference
- **Local Model Support**: llama.cpp integration for offline inference
- **Cloud Inference**: Groq API integration for high-speed cloud processing
- **Configurable Parameters**: Temperature, top-p, top-k, frequency penalty
- **Multi-core Optimization**: Optimized for multi-core systems
- **Model Switching**: Dynamic model selection based on requirements

### ğŸŒ Multi-Platform Integration
- **Telegram Bot**: Full-featured bot with voice and text support
- **REST API**: Comprehensive API for third-party integrations
- **Web UI Support**: Ready for web interface development
- **Mobile-Ready**: Optimized architecture for mobile applications
- **Webhook Support**: Real-time communication capabilities

### ğŸ™ï¸ Advanced Voice Processing
- **Multiple TTS Engines**: ElevenLabs, Coqui XTTS, Groq PlayAI
- **Voice Cloning**: Custom voice training and cloning capabilities
- **Audio Processing**: Advanced audio manipulation and enhancement
- **Real-time Streaming**: Low-latency voice streaming
- **Voice Quality Optimization**: Enhanced audio quality and clarity


## ğŸ“ Project Structure

```
polaris-v2-api/
â”œâ”€â”€ ğŸš€ polaris_api/          # Core Polaris API (LLM, Prompt, Memory)
â”‚   â”œâ”€â”€ polaris_main.py         # ğŸ”§ Main API logic and request handling
â”‚   â”œâ”€â”€ polaris_logger.py       # ğŸ“œ Structured logging for requests/events
â”‚   â”œâ”€â”€ polaris_keywords.py     # ğŸ§  Long-term keyword memory system
â”‚   â”œâ”€â”€ polaris_prompt.py       # ğŸ¯ AI instruction and system prompts
â”‚   â”œâ”€â”€ llm_loader.py           # ğŸ” LLM router and model selection logic
â”‚   â”œâ”€â”€ llm_local.py            # ğŸ  Local inference via llama.cpp
â”‚   â”œâ”€â”€ llm_groq.py             # â˜ï¸ Remote inference via Groq API
â”‚   â”œâ”€â”€ requirements.txt        # ğŸ“¦ Python dependencies
â”‚   â”œâ”€â”€ env-example.txt         # ğŸ” Environment variables template
â”‚   â””â”€â”€ polaris.log             # ğŸ“‹ Application logs
â”œâ”€â”€ ğŸ”— polaris_integrations/ # Bridges to external services (voice, audio, etc.)
â”‚   â”œâ”€â”€ main.py                 # ğŸ”Œ Entry point for integrations (TTS, Telegram, etc.)
â”‚   â”œâ”€â”€ tts_router.py           # ğŸ—£ï¸ Smart TTS engine dispatcher
â”‚   â”œâ”€â”€ tts_engines/
â”‚   â”‚ â”œâ”€â”€ coqui.py              # ğŸ™ï¸ Local voice synthesis (XTTS)
â”‚   â”‚ â”œâ”€â”€ eleven.py             # ğŸ§ ElevenLabs cloud-based TTS
â”‚   â”‚ â””â”€â”€ groq.py               # ğŸ¤ Groq PlayAI TTS integration
â”‚   â”œâ”€â”€ polaris-voice.wav       # ğŸ¼ Custom voice reference sample
â”‚   â”œâ”€â”€ requirements.txt        # ğŸ“¦ Integration dependencies
â”‚   â””â”€â”€ env-example.txt         # ğŸ” Integration environment config
â”œâ”€â”€ ğŸ³ polaris_setup/        # Infrastructure, benchmarking, and OS prep
â”‚   â”œâ”€â”€ data-flush.py           # ğŸ› ï¸ Memory cleanup and maintenance script
â”‚   â”œâ”€â”€ mongodb-compose.yml     # ğŸ—„ï¸ MongoDB container orchestration
â”‚   â””â”€â”€ polaris-os-tunner.sh    # ğŸ› ï¸ System tuning script (Debian/Ubuntu)
â”œâ”€â”€ ğŸ“– local-setup.sh           # ğŸš€ Interactive one-command setup script
â”œâ”€â”€ ğŸ§ª Makefile                 # ğŸ› ï¸ Dev workflow commands and automation
â”œâ”€â”€ ğŸ“‹ .gitignore               # ğŸš« Git ignore patterns
â””â”€â”€ ğŸ“– README.md                # ğŸ“š This documentation
```

### ğŸŒ API Endpoints

**Polaris API (Port 8000):**
- `POST /inference/` - Main inference endpoint (requires JWT auth)
- `POST /upload-pdf/` - PDF document processing
- `GET /health` - System health check
- `POST /auth/token` - Get JWT token
- `GET /auth/verify` - Verify JWT token

**Polaris Integrations (Port 8010):**
- `POST /audio-inference/` - Audio processing with STT + TTS
- `GET /audio/{filename}` - Audio file access
- `GET /metrics` - Prometheus metrics


## ğŸš€ Quick Start

### ğŸ”§ Prerequisites

- **Python 3.10+** (recommended: 3.11)
- **Docker & Docker Compose** (for MongoDB)
- **8GB+ RAM** (for local inference)
- **NVIDIA GPU** (optional, for accelerated inference)
- **FFmpeg** (for audio processing)

### ğŸ¯ One-Command Setup

```bash
git clone https://github.com/Tech-Tweakers/polaris-v2-api.git
cd polaris-v2-api
chmod +x local-setup.sh
./local-setup.sh
```

The interactive setup will:
- âœ… Install all dependencies
- âœ… Create environment files (.env)
- âœ… Download AI models (LLaMA 3 8B)
- âœ… Start MongoDB container
- âœ… Configure webhooks
- âœ… Launch all services

### ğŸ® Interactive Menu

The `local-setup.sh` provides an interactive menu with options:

```
==================================
      ğŸš€ Polaris v2.1 - Menu        
==================================
1) ğŸ› ï¸  ConfiguraÃ§Ã£o inicial (Instalar dependÃªncias)
2) ğŸ“  Criar .env para API e Bot
3) ğŸ¤–  Baixar modelo LLaMA 3
4) ğŸ³  Subir MongoDB e Mongo Express
5) ğŸŒ  Configurar Ngrok + Webhook Telegram
6) ğŸš€  Iniciar Polaris API
7) ğŸ¤–  Iniciar Polaris Integrations
8) ğŸ”„  Iniciar tudo (DB, API, Integrations, Ngrok)
9) ğŸ›‘  Parar tudo
10) ğŸ”„ Reiniciar tudo
0) âŒ  Sair
```


## ğŸ› ï¸ Manual Installation

<details>
<summary>Click to view manual installation instructions</summary>

**1. Setup Dependencies**

```bash
make install
```

**2. Create Environment Files**

```bash
# Criar .env com chaves seguras
make create-env-api

# Se precisar regenerar as chaves
make regenerate-env-api

# Criar .env do bot
make create-env-bot
```

**3. Download LLM Model for Local Inference**

```bash
make download-model
```

**4. Setup and Start MongoDB**

```bash
make start-db
```

**5. Start All Services**

```bash
make start-all
```

**6. Verify Installation**

```bash
# Test main API
curl -X POST http://localhost:8000/inference/ \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello, Polaris!", "session_id": "test123"}'

# Test health check
curl http://localhost:8000/health

# Test integrations API
curl http://localhost:8010/metrics
```

</details>


## âš™ï¸ Configuration

### `.env` â€“ Polaris API

```env
# Model Configuration
MODEL_PATH="../models/llama3-7B.safetensors"
NUM_CORES=16
MODEL_CONTEXT_SIZE=4096
MODEL_BATCH_SIZE=8

# Memory and Context Settings
MONGODB_HISTORY=4
LANGCHAIN_HISTORY=10

# LLM Hyperparameters
TEMPERATURE=0.3
TOP_P=0.7
TOP_K=70
FREQUENCY_PENALTY=3

# Database Connections
USE_MONGODB=true
MONGO_URI="mongodb://root:examplepassword@localhost:27017/polaris_db?authSource=admin"

# API Keys
HF_TOKEN="hf_yourhuggingfaceapikey"  # Required for sentence transformers
GROQ_API_KEY="gsk_yourgroqapikey"    # Required for Groq inference

# Monitoring
USE_PUSHGATEWAY=false
```

### `.env` â€“ Polaris Integrations

```env
# Telegram Configuration
TELEGRAM_TOKEN="your_telegram_bot_token"
POLARIS_API_URL="http://localhost:8000/inference/"

# TTS Engine Selection
TTS_ENGINE="coqui"  # Options: eleven / coqui / groq

# ElevenLabs Configuration
ELEVEN_API_KEY="your_elevenlabs_api_key"
ELEVEN_VOICE_ID="yM93hbw8Qtvdma2wCnJG"
ELEVEN_MODEL_ID="eleven_multilingual_v2"

# Groq Configuration
GROQ_API_KEY="gsk_your-groq-api-key"

# Coqui Configuration
COQUI_SPEAKER_WAV="polaris-voice.wav"

# Public URL (for webhooks)
PUBLIC_URL="https://your-ngrok-url.ngrok.io"

# HuggingFace Token
HF_TOKEN="hf_yourhuggingfaceapikey"
```


## ğŸ§ª Testing

### API Testing

**Get JWT Token:**

```bash
curl -X POST http://localhost:8000/auth/token \
  -H "Content-Type: application/json" \
  -d '{
    "client_name": "polaris_bot",
    "client_secret": "bot-secret"
  }'
```

**Basic Inference Test (with JWT):**

```bash
# First get token
TOKEN=$(curl -s -X POST http://localhost:8000/auth/token \
  -H "Content-Type: application/json" \
  -d '{"client_name": "polaris_bot", "client_secret": "bot-secret"}' | jq -r '.access_token')

# Then use token
curl -X POST http://localhost:8000/inference/ \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "prompt": "Hello, Polaris! How are you today?",
    "session_id": "test123"
  }'
```

**PDF Upload Test:**

```bash
curl -X POST http://localhost:8000/upload-pdf/ \
  -F "file=@document.pdf" \
  -F "session_id=test123"
```

### Integrations Testing

**Audio Inference Test:**

```bash
curl -X POST http://localhost:8010/audio-inference/ \
  -F "audio=@voice_message.webm" \
  -F "session_id=test123"
```

**Audio File Access:**

```bash
curl http://localhost:8010/audio/filename.mp3
```

**Metrics Endpoint:**

```bash
curl http://localhost:8010/metrics
```

### Telegram Bot Testing

1. Start the integrations service: `make start-integrations`
2. Send a message to your Telegram bot
3. Check logs for response confirmation


## ğŸ“Š Monitoring & Metrics

### Logging

Polaris uses structured logging with different levels:
- **INFO**: General application events
- **DEBUG**: Detailed debugging information
- **WARNING**: Non-critical issues
- **ERROR**: Critical errors

### Metrics

The system provides metrics for:
- Request/response times
- Memory usage
- Model inference performance
- Error rates
- TTS processing times

### Health Checks

```bash
# API Health Check
curl http://localhost:8000/health

# MongoDB Health Check
curl http://localhost:27017

# Metrics Check
curl http://localhost:8010/metrics
```


## ğŸ”§ Development

### Available Make Commands

```bash
# Installation
make install              # Install all dependencies
make setup               # Initial system setup

# Model Management
make download-model      # Download LLaMA 3 model
make clean-models        # Remove downloaded models

# Database Management
make start-db           # Start MongoDB
make stop-db            # Stop MongoDB
make restart-db         # Restart MongoDB

# Service Management
make start-api          # Start Polaris API
make start-integrations # Start Polaris Integrations
make start-all          # Start all services
make stop-all           # Stop all services
make restart-all        # Restart all services

# Environment Setup
make create-env-api     # Create API .env file with secure keys
make regenerate-env-api # Regenerate API .env with new keys
make create-env-bot     # Create Integrations .env file

# Development
make test               # Run tests
make lint               # Run linting
make format             # Format code
```

### Development Workflow

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes**
4. **Test thoroughly**: `make test`
5. **Commit your changes**: `git commit -m 'Add amazing feature'`
6. **Push to the branch**: `git push origin feature/amazing-feature`
7. **Open a Pull Request**


## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Areas for Contribution

- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“š Documentation improvements
- ğŸ§ª Test coverage
- ğŸ¨ UI/UX improvements
- ğŸ”§ Performance optimizations

### Code Style

- Follow PEP 8 for Python code
- Use meaningful variable and function names
- Add docstrings to all functions
- Include type hints where appropriate
- Write comprehensive tests

---

## â¤ï¸ Credits

Developed with â¤ï¸ by **Tech-Tweakers** team.

### Acknowledgments
- **Groq** for high-performance inference
- **ElevenLabs** for voice synthesis
- **HuggingFace** for model hosting
- **MongoDB** for database solutions
- **FastAPI** for the web framework

---

<div align="center">

**ğŸŒŸ Star this repository if you find it useful! ğŸŒŸ**

[![GitHub stars](https://img.shields.io/github/stars/Tech-Tweakers/polaris-v2-api?style=social)](https://github.com/Tech-Tweakers/polaris-v2-api/stargazers)

</div>

